{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141e3750-cdbb-45de-bfb9-dd24b8f943d8",
   "metadata": {},
   "source": [
    "### Этот ноутбук содержит процесс создания программы для семантического поиска мемов по текстовому запросу пользователя.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281b9dc-6f70-479f-891c-ede5bd10243a",
   "metadata": {},
   "source": [
    "#### Как работает программа?\n",
    "- **Пользователь пишет короткое текстовое описание ситуации**, к которой он хочет подобрать мемы.\n",
    "- Запрос передается в **языковую модель-трансформер**, которая превращает запрос в эмбеддинг предложения.\n",
    "- Далее идет поиск наиболее подходящего мема из датасета с помощью библиотеки **faiss**, основанный на сравнении эмбеддинга запроса и эмбеддингов текстовых описаний мемов на основе **косинусного расстояния**.\n",
    "\n",
    "#### Какие данные используются?\n",
    "- Собранные данные с сайта **memepedia.ru** - архив русских мемов.\n",
    "- Данные собраны с помощью библиотеки **Selenium** и представляют собой csv-файл с названиями мемов, их текстовым описанием и ссылкой на страницу.\n",
    "- В датасете примерно **2000 мемов**.\n",
    "\n",
    "#### Используемые библиотеки\n",
    "- **pandas, numpy, huggingface, sentence_transformers, faiss, torch**\n",
    "\n",
    "#### План проекта\n",
    "1. **Чистка данных** после сбора - удаление пустых строк и дубликатов.\n",
    "2. Поиск наиболее подходящей **языковой модели**. Использование готовых моделей-трансформеров доступных на huggingface сначала без дополнительного обучения.\n",
    "3. Настройка поиска **faiss**.\n",
    "4. **Дообучение подходящей модели** на собственных данных. Использование ChatGPT для искусственного дополнения датасета примерами запросов пользователей.\n",
    "5. **Деплоймент программы** в виде телеграм-бота (не описан в этом ноутбуке).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930462f9-9153-4aed-88c5-bba8c7b2344c",
   "metadata": {},
   "source": [
    "#### Ссылки на ресурсы\n",
    "- [Курс по NLP для работы с трансформерами и faiss](https://huggingface.co/learn/nlp-course/chapter5/6?fw=tf)\n",
    "- [Semantic Search with S-BERT is all you need](https://medium.com/mlearning-ai/semantic-search-with-s-bert-is-all-you-need-951bc710e160)\n",
    "- [From zero to semantic search embedding model](https://blog.metarank.ai/from-zero-to-semantic-search-embedding-model-592e16d94b61)\n",
    "- [Train and Fine-Tune Sentence Transformers Models](https://huggingface.co/blog/how-to-train-sentence-transformers)\n",
    "- [How to easy preprocess Russian text](https://www.kaggle.com/code/alxmamaev/how-to-easy-preprocess-russian-text)\n",
    "- [The Art of Pooling Embeddings](https://blog.ml6.eu/the-art-of-pooling-embeddings-c56575114cf8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77073cb-52f9-4a0b-a1ce-8a0293ddf9b3",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных и чистка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9bebe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5a1f3-97e1-4c8b-969e-3dd8f522a5e3",
   "metadata": {},
   "source": [
    "Я собираюсь использовать модели-трансформеры, поэтому единственный этап чистки данных здесь - удаление дубликатов, пустых строк или тех, что попали в датасет случайно при парсинге. Однако я оставила функции, которые изначально использовала для чистки.\n",
    "- Удаление пунктуации, приведение в нижний регистр и словарную форму не требуется, т.к. трансформеры учитывают общий контекст слов в предложении и в \"сыром\" формате без обработки может содержаться важная информация. Я пробовала чистить данные ради эксперимента, но это не улучшило качество поиска.\n",
    "- Также пробовала удалять самые частно встречающиеся слова (мем, тренд, это и т.д.), это тоже не повлияло на результат.\n",
    "- Единственный вопрос, который остается открытым - исправление орфографических ошибок в сообщении пользователя, т.к. они могут повлиять на результат поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1d1d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>header</th>\n",
       "      <th>link</th>\n",
       "      <th>meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>А мне X дороже Y</td>\n",
       "      <td>https://memepedia.ru/a-mne-x-dorozhe-y/</td>\n",
       "      <td>Мем “А мне X дороже Y” (или “А мне X важнее Y”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Рыба с большой головой смотрит на дайвера</td>\n",
       "      <td>https://memepedia.ru/ryba-s-bolshoj-golovoj-sm...</td>\n",
       "      <td>В мемах, где рыба с большой головой смотрит на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Две девушки в черных платьях</td>\n",
       "      <td>https://memepedia.ru/dve-devushki-v-chernyx-pl...</td>\n",
       "      <td>Мем “Две девушки в черных платьях” показывает ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Пивной ежик</td>\n",
       "      <td>https://memepedia.ru/pivnoj-ezhik/</td>\n",
       "      <td>Мем “Пивной ежик” – это забавный тренд, которы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Война древних русов с ящерами</td>\n",
       "      <td>https://memepedia.ru/vojna-drevnix-rusov-s-yas...</td>\n",
       "      <td>Война древних русов с ящерами или битва русов ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>133</td>\n",
       "      <td>Мальчик у доски</td>\n",
       "      <td>https://memepedia.ru/malchik-u-doski/</td>\n",
       "      <td>Картинку с мальчиком у доски и словом “Тут” из...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>134</td>\n",
       "      <td>Не расстраивай Леонида Аркадьевича</td>\n",
       "      <td>https://memepedia.ru/ne-rasstraivaj-leonida-ar...</td>\n",
       "      <td>Мем “Не расстраивай Леонида Аркадьевича” испол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>134</td>\n",
       "      <td>Девочка с хвостиками</td>\n",
       "      <td>https://memepedia.ru/mem-devochka-s-xvostikami/</td>\n",
       "      <td>Мем с девочкой с хвостиками используется для в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>134</td>\n",
       "      <td>Танец Медведева</td>\n",
       "      <td>https://memepedia.ru/tanec-medvedeva/</td>\n",
       "      <td>Шутки про танец Медведева обычно используют, ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>134</td>\n",
       "      <td>Мем он (девушка шепчет подруге на ухо)</td>\n",
       "      <td>https://memepedia.ru/mem-on-devushka-shepchet-...</td>\n",
       "      <td>Мем “Девушка шепчет на ухо подруге” использует...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2243 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      page                                     header  \\\n",
       "0        1                           А мне X дороже Y   \n",
       "1        1  Рыба с большой головой смотрит на дайвера   \n",
       "2        1               Две девушки в черных платьях   \n",
       "3        1                                Пивной ежик   \n",
       "4        1              Война древних русов с ящерами   \n",
       "...    ...                                        ...   \n",
       "3079   133                            Мальчик у доски   \n",
       "3085   134         Не расстраивай Леонида Аркадьевича   \n",
       "3086   134                       Девочка с хвостиками   \n",
       "3087   134                            Танец Медведева   \n",
       "3088   134     Мем он (девушка шепчет подруге на ухо)   \n",
       "\n",
       "                                                   link  \\\n",
       "0               https://memepedia.ru/a-mne-x-dorozhe-y/   \n",
       "1     https://memepedia.ru/ryba-s-bolshoj-golovoj-sm...   \n",
       "2     https://memepedia.ru/dve-devushki-v-chernyx-pl...   \n",
       "3                    https://memepedia.ru/pivnoj-ezhik/   \n",
       "4     https://memepedia.ru/vojna-drevnix-rusov-s-yas...   \n",
       "...                                                 ...   \n",
       "3079              https://memepedia.ru/malchik-u-doski/   \n",
       "3085  https://memepedia.ru/ne-rasstraivaj-leonida-ar...   \n",
       "3086    https://memepedia.ru/mem-devochka-s-xvostikami/   \n",
       "3087              https://memepedia.ru/tanec-medvedeva/   \n",
       "3088  https://memepedia.ru/mem-on-devushka-shepchet-...   \n",
       "\n",
       "                                                meaning  \n",
       "0     Мем “А мне X дороже Y” (или “А мне X важнее Y”...  \n",
       "1     В мемах, где рыба с большой головой смотрит на...  \n",
       "2     Мем “Две девушки в черных платьях” показывает ...  \n",
       "3     Мем “Пивной ежик” – это забавный тренд, которы...  \n",
       "4     Война древних русов с ящерами или битва русов ...  \n",
       "...                                                 ...  \n",
       "3079  Картинку с мальчиком у доски и словом “Тут” из...  \n",
       "3085  Мем “Не расстраивай Леонида Аркадьевича” испол...  \n",
       "3086  Мем с девочкой с хвостиками используется для в...  \n",
       "3087  Шутки про танец Медведева обычно используют, ч...  \n",
       "3088  Мем “Девушка шепчет на ухо подруге” использует...  \n",
       "\n",
       "[2243 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_data = pd.read_csv('meme_dataset.csv', index_col=0)\n",
    "\n",
    "# чистим текстовые данные\n",
    "meme_data = meme_data.drop(index=meme_data[meme_data['meaning'] == 'Галерея'].index)\n",
    "meme_data = meme_data.drop(index=meme_data[meme_data['meaning']=='\\xa0'].index)\n",
    "meme_data = meme_data.dropna()\n",
    "meme_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7db83fdf-c65d-4979-9548-8dbec6b943da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#убираем пунктуацию и ссылки\n",
    "\n",
    "import re, string\n",
    "\n",
    "def remove_symbols(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower().replace('– ', '').replace('“', '').replace('”', '').replace(u'\\xa0', u' ')\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5b93b448-a9f6-4f87-95a0-54e42eb32401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#лемматизируем текст (приведем слова в словарную форму)\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "mystem = Mystem()\n",
    "\n",
    "def lemmatize_text(x):\n",
    "    text = mystem.lemmatize(x)\n",
    "    return ('').join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b349a2f0-fe9a-406d-b17f-05ce2039ef21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#удаляем стоп-слова\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('russian')\n",
    "\n",
    "#оставим местоимения\n",
    "russian_pronouns = 'я, мы, ты, вы, он, она, оно, они, себя, мой, твой, ваш, наш, свой, его, ее, их, то, это, тот, этот, такой, таков, столько, весь, всякий, сам, самый, каждый, любой, иной, другой, кто, что, какой, каков, чей, сколько, никто, ничто, некого, нечего, никакой, ничей, нисколько,кто-то, кое-кто, кто-нибудь, кто-либо, что-то, кое-что, что-нибудь, что-либо, какой-то, какой-либо, какой-нибудь, некто, нечто, некоторый, некий'\n",
    "russian_pronouns = russian_pronouns.split(', ')\n",
    "\n",
    "for i_elem in stop_words:\n",
    "    if i_elem in russian_pronouns:\n",
    "        stop_words.remove(i_elem)\n",
    "\n",
    "def remove_stopword(x):\n",
    "    filtered_text = []\n",
    "    \n",
    "    for i_word in x.split():\n",
    "        if i_word not in stop_words:\n",
    "            filtered_text.append(i_word)\n",
    "            \n",
    "    return (' ').join(filtered_text)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f421de6-dabd-4965-893d-cebc6908e53e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c4eae_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c4eae_row1_col1 {\n",
       "  background-color: #74b3d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row2_col1 {\n",
       "  background-color: #9ac8e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row3_col1 {\n",
       "  background-color: #a0cbe2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row4_col1 {\n",
       "  background-color: #d0e1f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row5_col1 {\n",
       "  background-color: #d1e2f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row6_col1 {\n",
       "  background-color: #d3e3f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row7_col1 {\n",
       "  background-color: #d3e4f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row8_col1 {\n",
       "  background-color: #d9e8f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row9_col1 {\n",
       "  background-color: #dceaf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row10_col1, #T_c4eae_row11_col1 {\n",
       "  background-color: #ddeaf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row12_col1 {\n",
       "  background-color: #dfebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row13_col1, #T_c4eae_row14_col1 {\n",
       "  background-color: #e0ecf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row15_col1 {\n",
       "  background-color: #e2edf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row16_col1, #T_c4eae_row17_col1 {\n",
       "  background-color: #e4eff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row18_col1, #T_c4eae_row19_col1, #T_c4eae_row20_col1 {\n",
       "  background-color: #e5eff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row21_col1, #T_c4eae_row22_col1 {\n",
       "  background-color: #e8f1fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row23_col1, #T_c4eae_row24_col1 {\n",
       "  background-color: #e9f2fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row25_col1 {\n",
       "  background-color: #eaf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row26_col1 {\n",
       "  background-color: #ebf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row27_col1, #T_c4eae_row28_col1, #T_c4eae_row29_col1 {\n",
       "  background-color: #eef5fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row30_col1, #T_c4eae_row31_col1, #T_c4eae_row32_col1 {\n",
       "  background-color: #eff6fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row33_col1 {\n",
       "  background-color: #f0f6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row34_col1, #T_c4eae_row35_col1, #T_c4eae_row36_col1, #T_c4eae_row37_col1 {\n",
       "  background-color: #f1f7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row38_col1, #T_c4eae_row39_col1, #T_c4eae_row40_col1 {\n",
       "  background-color: #f2f7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row41_col1, #T_c4eae_row42_col1, #T_c4eae_row43_col1, #T_c4eae_row44_col1 {\n",
       "  background-color: #f2f8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row45_col1, #T_c4eae_row46_col1 {\n",
       "  background-color: #f3f8fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row47_col1, #T_c4eae_row48_col1, #T_c4eae_row49_col1, #T_c4eae_row50_col1, #T_c4eae_row51_col1 {\n",
       "  background-color: #f4f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row52_col1, #T_c4eae_row53_col1, #T_c4eae_row54_col1, #T_c4eae_row55_col1, #T_c4eae_row56_col1, #T_c4eae_row57_col1, #T_c4eae_row58_col1, #T_c4eae_row59_col1, #T_c4eae_row60_col1 {\n",
       "  background-color: #f5f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row61_col1, #T_c4eae_row62_col1, #T_c4eae_row63_col1, #T_c4eae_row64_col1, #T_c4eae_row65_col1, #T_c4eae_row66_col1, #T_c4eae_row67_col1, #T_c4eae_row68_col1, #T_c4eae_row69_col1, #T_c4eae_row70_col1, #T_c4eae_row71_col1 {\n",
       "  background-color: #f5fafe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row72_col1, #T_c4eae_row73_col1, #T_c4eae_row74_col1, #T_c4eae_row75_col1, #T_c4eae_row76_col1, #T_c4eae_row77_col1, #T_c4eae_row78_col1, #T_c4eae_row79_col1, #T_c4eae_row80_col1, #T_c4eae_row81_col1, #T_c4eae_row82_col1 {\n",
       "  background-color: #f6faff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c4eae_row83_col1, #T_c4eae_row84_col1, #T_c4eae_row85_col1, #T_c4eae_row86_col1, #T_c4eae_row87_col1, #T_c4eae_row88_col1, #T_c4eae_row89_col1, #T_c4eae_row90_col1, #T_c4eae_row91_col1, #T_c4eae_row92_col1, #T_c4eae_row93_col1, #T_c4eae_row94_col1, #T_c4eae_row95_col1, #T_c4eae_row96_col1, #T_c4eae_row97_col1, #T_c4eae_row98_col1, #T_c4eae_row99_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c4eae\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c4eae_level0_col0\" class=\"col_heading level0 col0\" >Common_words</th>\n",
       "      <th id=\"T_c4eae_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c4eae_row0_col0\" class=\"data row0 col0\" >мема</td>\n",
       "      <td id=\"T_c4eae_row0_col1\" class=\"data row0 col1\" >2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c4eae_row1_col0\" class=\"data row1 col0\" >который</td>\n",
       "      <td id=\"T_c4eae_row1_col1\" class=\"data row1 col1\" >1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c4eae_row2_col0\" class=\"data row2 col0\" >человек</td>\n",
       "      <td id=\"T_c4eae_row2_col1\" class=\"data row2 col1\" >818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c4eae_row3_col0\" class=\"data row3 col0\" >это</td>\n",
       "      <td id=\"T_c4eae_row3_col1\" class=\"data row3 col1\" >791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c4eae_row4_col0\" class=\"data row4 col0\" >становиться</td>\n",
       "      <td id=\"T_c4eae_row4_col1\" class=\"data row4 col1\" >463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c4eae_row5_col0\" class=\"data row5 col0\" >ситуация</td>\n",
       "      <td id=\"T_c4eae_row5_col1\" class=\"data row5 col1\" >445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c4eae_row6_col0\" class=\"data row6 col0\" >использоваться</td>\n",
       "      <td id=\"T_c4eae_row6_col1\" class=\"data row6 col1\" >430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c4eae_row7_col0\" class=\"data row7 col0\" >мочь</td>\n",
       "      <td id=\"T_c4eae_row7_col1\" class=\"data row7 col1\" >428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c4eae_row8_col0\" class=\"data row8 col0\" >часто</td>\n",
       "      <td id=\"T_c4eae_row8_col1\" class=\"data row8 col1\" >364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c4eae_row9_col0\" class=\"data row9 col0\" >показывать</td>\n",
       "      <td id=\"T_c4eae_row9_col1\" class=\"data row9 col1\" >331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c4eae_row10_col0\" class=\"data row10 col0\" >год</td>\n",
       "      <td id=\"T_c4eae_row10_col1\" class=\"data row10 col1\" >329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c4eae_row11_col0\" class=\"data row11 col0\" >фраза</td>\n",
       "      <td id=\"T_c4eae_row11_col1\" class=\"data row11 col1\" >324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c4eae_row12_col0\" class=\"data row12 col0\" >свой</td>\n",
       "      <td id=\"T_c4eae_row12_col1\" class=\"data row12 col1\" >309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c4eae_row13_col0\" class=\"data row13 col0\" >чтото</td>\n",
       "      <td id=\"T_c4eae_row13_col1\" class=\"data row13 col1\" >295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c4eae_row14_col0\" class=\"data row14 col0\" >например</td>\n",
       "      <td id=\"T_c4eae_row14_col1\" class=\"data row14 col1\" >292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c4eae_row15_col0\" class=\"data row15 col0\" >картинка</td>\n",
       "      <td id=\"T_c4eae_row15_col1\" class=\"data row15 col1\" >277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c4eae_row16_col0\" class=\"data row16 col0\" >слово</td>\n",
       "      <td id=\"T_c4eae_row16_col1\" class=\"data row16 col1\" >255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_c4eae_row17_col0\" class=\"data row17 col0\" >персонаж</td>\n",
       "      <td id=\"T_c4eae_row17_col1\" class=\"data row17 col1\" >254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_c4eae_row18_col0\" class=\"data row18 col0\" >самый</td>\n",
       "      <td id=\"T_c4eae_row18_col1\" class=\"data row18 col1\" >249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_c4eae_row19_col0\" class=\"data row19 col0\" >использовать</td>\n",
       "      <td id=\"T_c4eae_row19_col1\" class=\"data row19 col1\" >248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_c4eae_row20_col0\" class=\"data row20 col0\" >мем</td>\n",
       "      <td id=\"T_c4eae_row20_col1\" class=\"data row20 col1\" >248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_c4eae_row21_col0\" class=\"data row21 col0\" >разный</td>\n",
       "      <td id=\"T_c4eae_row21_col1\" class=\"data row21 col1\" >223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_c4eae_row22_col0\" class=\"data row22 col0\" >шутка</td>\n",
       "      <td id=\"T_c4eae_row22_col1\" class=\"data row22 col1\" >220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_c4eae_row23_col0\" class=\"data row23 col0\" >также</td>\n",
       "      <td id=\"T_c4eae_row23_col1\" class=\"data row23 col1\" >213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_c4eae_row24_col0\" class=\"data row24 col0\" >смысл</td>\n",
       "      <td id=\"T_c4eae_row24_col1\" class=\"data row24 col1\" >211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_c4eae_row25_col0\" class=\"data row25 col0\" >высмеивать</td>\n",
       "      <td id=\"T_c4eae_row25_col1\" class=\"data row25 col1\" >194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_c4eae_row26_col0\" class=\"data row26 col0\" >видео</td>\n",
       "      <td id=\"T_c4eae_row26_col1\" class=\"data row26 col1\" >191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_c4eae_row27_col0\" class=\"data row27 col0\" >пользователь</td>\n",
       "      <td id=\"T_c4eae_row27_col1\" class=\"data row27 col1\" >169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_c4eae_row28_col0\" class=\"data row28 col0\" >реакция</td>\n",
       "      <td id=\"T_c4eae_row28_col1\" class=\"data row28 col1\" >169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_c4eae_row29_col0\" class=\"data row29 col0\" >лицо</td>\n",
       "      <td id=\"T_c4eae_row29_col1\" class=\"data row29 col1\" >163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_c4eae_row30_col0\" class=\"data row30 col0\" >популярный</td>\n",
       "      <td id=\"T_c4eae_row30_col1\" class=\"data row30 col1\" >155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_c4eae_row31_col0\" class=\"data row31 col0\" >появляться</td>\n",
       "      <td id=\"T_c4eae_row31_col1\" class=\"data row31 col1\" >154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_c4eae_row32_col0\" class=\"data row32 col0\" >весь</td>\n",
       "      <td id=\"T_c4eae_row32_col1\" class=\"data row32 col1\" >153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_c4eae_row33_col0\" class=\"data row33 col0\" >говорить</td>\n",
       "      <td id=\"T_c4eae_row33_col1\" class=\"data row33 col1\" >143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_c4eae_row34_col0\" class=\"data row34 col0\" >первый</td>\n",
       "      <td id=\"T_c4eae_row34_col1\" class=\"data row34 col1\" >140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_c4eae_row35_col0\" class=\"data row35 col0\" >обычно</td>\n",
       "      <td id=\"T_c4eae_row35_col1\" class=\"data row35 col1\" >139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_c4eae_row36_col0\" class=\"data row36 col0\" >просто</td>\n",
       "      <td id=\"T_c4eae_row36_col1\" class=\"data row36 col1\" >134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_c4eae_row37_col0\" class=\"data row37 col0\" >—</td>\n",
       "      <td id=\"T_c4eae_row37_col1\" class=\"data row37 col1\" >134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_c4eae_row38_col0\" class=\"data row38 col0\" >герой</td>\n",
       "      <td id=\"T_c4eae_row38_col1\" class=\"data row38 col1\" >132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_c4eae_row39_col0\" class=\"data row39 col0\" >парень</td>\n",
       "      <td id=\"T_c4eae_row39_col1\" class=\"data row39 col1\" >128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_c4eae_row40_col0\" class=\"data row40 col0\" >делать</td>\n",
       "      <td id=\"T_c4eae_row40_col1\" class=\"data row40 col1\" >126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_c4eae_row41_col0\" class=\"data row41 col0\" >игра</td>\n",
       "      <td id=\"T_c4eae_row41_col1\" class=\"data row41 col1\" >125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_c4eae_row42_col0\" class=\"data row42 col0\" >девушка</td>\n",
       "      <td id=\"T_c4eae_row42_col1\" class=\"data row42 col1\" >120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_c4eae_row43_col0\" class=\"data row43 col0\" >любой</td>\n",
       "      <td id=\"T_c4eae_row43_col1\" class=\"data row43 col1\" >119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_c4eae_row44_col0\" class=\"data row44 col0\" >фильм</td>\n",
       "      <td id=\"T_c4eae_row44_col1\" class=\"data row44 col1\" >118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_c4eae_row45_col0\" class=\"data row45 col0\" >сделать</td>\n",
       "      <td id=\"T_c4eae_row45_col1\" class=\"data row45 col1\" >116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_c4eae_row46_col0\" class=\"data row46 col0\" >очень</td>\n",
       "      <td id=\"T_c4eae_row46_col1\" class=\"data row46 col1\" >110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_c4eae_row47_col0\" class=\"data row47 col0\" >выражать</td>\n",
       "      <td id=\"T_c4eae_row47_col1\" class=\"data row47 col1\" >109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_c4eae_row48_col0\" class=\"data row48 col0\" >песня</td>\n",
       "      <td id=\"T_c4eae_row48_col1\" class=\"data row48 col1\" >107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_c4eae_row49_col0\" class=\"data row49 col0\" >означать</td>\n",
       "      <td id=\"T_c4eae_row49_col1\" class=\"data row49 col1\" >106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_c4eae_row50_col0\" class=\"data row50 col0\" >правило</td>\n",
       "      <td id=\"T_c4eae_row50_col1\" class=\"data row50 col1\" >105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_c4eae_row51_col0\" class=\"data row51 col0\" >случай</td>\n",
       "      <td id=\"T_c4eae_row51_col1\" class=\"data row51 col1\" >104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_c4eae_row52_col0\" class=\"data row52 col0\" >иллюстрировать</td>\n",
       "      <td id=\"T_c4eae_row52_col1\" class=\"data row52 col1\" >102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_c4eae_row53_col0\" class=\"data row53 col0\" >образ</td>\n",
       "      <td id=\"T_c4eae_row53_col1\" class=\"data row53 col1\" >101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_c4eae_row54_col0\" class=\"data row54 col0\" >вещь</td>\n",
       "      <td id=\"T_c4eae_row54_col1\" class=\"data row54 col1\" >101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_c4eae_row55_col0\" class=\"data row55 col0\" >кот</td>\n",
       "      <td id=\"T_c4eae_row55_col1\" class=\"data row55 col1\" >101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_c4eae_row56_col0\" class=\"data row56 col0\" >различный</td>\n",
       "      <td id=\"T_c4eae_row56_col1\" class=\"data row56 col1\" >101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_c4eae_row57_col0\" class=\"data row57 col0\" >являться</td>\n",
       "      <td id=\"T_c4eae_row57_col1\" class=\"data row57 col1\" >100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_c4eae_row58_col0\" class=\"data row58 col0\" >качество</td>\n",
       "      <td id=\"T_c4eae_row58_col1\" class=\"data row58 col1\" >98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_c4eae_row59_col0\" class=\"data row59 col0\" >ироничный</td>\n",
       "      <td id=\"T_c4eae_row59_col1\" class=\"data row59 col1\" >96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "      <td id=\"T_c4eae_row60_col0\" class=\"data row60 col0\" >иметь</td>\n",
       "      <td id=\"T_c4eae_row60_col1\" class=\"data row60 col1\" >96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "      <td id=\"T_c4eae_row61_col0\" class=\"data row61 col0\" >время</td>\n",
       "      <td id=\"T_c4eae_row61_col1\" class=\"data row61 col1\" >94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "      <td id=\"T_c4eae_row62_col0\" class=\"data row62 col0\" >изза</td>\n",
       "      <td id=\"T_c4eae_row62_col1\" class=\"data row62 col1\" >94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
       "      <td id=\"T_c4eae_row63_col0\" class=\"data row63 col0\" >поэтому</td>\n",
       "      <td id=\"T_c4eae_row63_col1\" class=\"data row63 col1\" >94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
       "      <td id=\"T_c4eae_row64_col0\" class=\"data row64 col0\" >похожий</td>\n",
       "      <td id=\"T_c4eae_row64_col1\" class=\"data row64 col1\" >94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row65\" class=\"row_heading level0 row65\" >65</th>\n",
       "      <td id=\"T_c4eae_row65_col0\" class=\"data row65 col0\" >известный</td>\n",
       "      <td id=\"T_c4eae_row65_col1\" class=\"data row65 col1\" >92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row66\" class=\"row_heading level0 row66\" >66</th>\n",
       "      <td id=\"T_c4eae_row66_col0\" class=\"data row66 col0\" >тема</td>\n",
       "      <td id=\"T_c4eae_row66_col1\" class=\"data row66 col1\" >92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row67\" class=\"row_heading level0 row67\" >67</th>\n",
       "      <td id=\"T_c4eae_row67_col0\" class=\"data row67 col0\" >жизнь</td>\n",
       "      <td id=\"T_c4eae_row67_col1\" class=\"data row67 col1\" >90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row68\" class=\"row_heading level0 row68\" >68</th>\n",
       "      <td id=\"T_c4eae_row68_col0\" class=\"data row68 col0\" >сеть</td>\n",
       "      <td id=\"T_c4eae_row68_col1\" class=\"data row68 col1\" >89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row69\" class=\"row_heading level0 row69\" >69</th>\n",
       "      <td id=\"T_c4eae_row69_col0\" class=\"data row69 col0\" >значение</td>\n",
       "      <td id=\"T_c4eae_row69_col1\" class=\"data row69 col1\" >89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row70\" class=\"row_heading level0 row70\" >70</th>\n",
       "      <td id=\"T_c4eae_row70_col0\" class=\"data row70 col0\" >ктото</td>\n",
       "      <td id=\"T_c4eae_row70_col1\" class=\"data row70 col1\" >88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row71\" class=\"row_heading level0 row71\" >71</th>\n",
       "      <td id=\"T_c4eae_row71_col0\" class=\"data row71 col0\" >называть</td>\n",
       "      <td id=\"T_c4eae_row71_col1\" class=\"data row71 col1\" >88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row72\" class=\"row_heading level0 row72\" >72</th>\n",
       "      <td id=\"T_c4eae_row72_col0\" class=\"data row72 col0\" >формат</td>\n",
       "      <td id=\"T_c4eae_row72_col1\" class=\"data row72 col1\" >87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row73\" class=\"row_heading level0 row73\" >73</th>\n",
       "      <td id=\"T_c4eae_row73_col0\" class=\"data row73 col0\" >помощь</td>\n",
       "      <td id=\"T_c4eae_row73_col1\" class=\"data row73 col1\" >86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row74\" class=\"row_heading level0 row74\" >74</th>\n",
       "      <td id=\"T_c4eae_row74_col0\" class=\"data row74 col0\" >хотеть</td>\n",
       "      <td id=\"T_c4eae_row74_col1\" class=\"data row74 col1\" >86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row75\" class=\"row_heading level0 row75\" >75</th>\n",
       "      <td id=\"T_c4eae_row75_col0\" class=\"data row75 col0\" >дело</td>\n",
       "      <td id=\"T_c4eae_row75_col1\" class=\"data row75 col1\" >86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row76\" class=\"row_heading level0 row76\" >76</th>\n",
       "      <td id=\"T_c4eae_row76_col0\" class=\"data row76 col0\" >фотография</td>\n",
       "      <td id=\"T_c4eae_row76_col1\" class=\"data row76 col1\" >84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row77\" class=\"row_heading level0 row77\" >77</th>\n",
       "      <td id=\"T_c4eae_row77_col0\" class=\"data row77 col0\" >выражение</td>\n",
       "      <td id=\"T_c4eae_row77_col1\" class=\"data row77 col1\" >83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row78\" class=\"row_heading level0 row78\" >78</th>\n",
       "      <td id=\"T_c4eae_row78_col0\" class=\"data row78 col0\" >автор</td>\n",
       "      <td id=\"T_c4eae_row78_col1\" class=\"data row78 col1\" >83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row79\" class=\"row_heading level0 row79\" >79</th>\n",
       "      <td id=\"T_c4eae_row79_col0\" class=\"data row79 col0\" >ролик</td>\n",
       "      <td id=\"T_c4eae_row79_col1\" class=\"data row79 col1\" >82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row80\" class=\"row_heading level0 row80\" >80</th>\n",
       "      <td id=\"T_c4eae_row80_col0\" class=\"data row80 col0\" >оригинальный</td>\n",
       "      <td id=\"T_c4eae_row80_col1\" class=\"data row80 col1\" >82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row81\" class=\"row_heading level0 row81\" >81</th>\n",
       "      <td id=\"T_c4eae_row81_col0\" class=\"data row81 col0\" >явление</td>\n",
       "      <td id=\"T_c4eae_row81_col1\" class=\"data row81 col1\" >81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row82\" class=\"row_heading level0 row82\" >82</th>\n",
       "      <td id=\"T_c4eae_row82_col0\" class=\"data row82 col0\" >символизировать</td>\n",
       "      <td id=\"T_c4eae_row82_col1\" class=\"data row82 col1\" >80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row83\" class=\"row_heading level0 row83\" >83</th>\n",
       "      <td id=\"T_c4eae_row83_col0\" class=\"data row83 col0\" >кадр</td>\n",
       "      <td id=\"T_c4eae_row83_col1\" class=\"data row83 col1\" >79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row84\" class=\"row_heading level0 row84\" >84</th>\n",
       "      <td id=\"T_c4eae_row84_col0\" class=\"data row84 col0\" >интернет</td>\n",
       "      <td id=\"T_c4eae_row84_col1\" class=\"data row84 col1\" >79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row85\" class=\"row_heading level0 row85\" >85</th>\n",
       "      <td id=\"T_c4eae_row85_col0\" class=\"data row85 col0\" >вид</td>\n",
       "      <td id=\"T_c4eae_row85_col1\" class=\"data row85 col1\" >78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row86\" class=\"row_heading level0 row86\" >86</th>\n",
       "      <td id=\"T_c4eae_row86_col0\" class=\"data row86 col0\" >мужчина</td>\n",
       "      <td id=\"T_c4eae_row86_col1\" class=\"data row86 col1\" >77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row87\" class=\"row_heading level0 row87\" >87</th>\n",
       "      <td id=\"T_c4eae_row87_col0\" class=\"data row87 col0\" >начинать</td>\n",
       "      <td id=\"T_c4eae_row87_col1\" class=\"data row87 col1\" >77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row88\" class=\"row_heading level0 row88\" >88</th>\n",
       "      <td id=\"T_c4eae_row88_col0\" class=\"data row88 col0\" >обыгрывать</td>\n",
       "      <td id=\"T_c4eae_row88_col1\" class=\"data row88 col1\" >77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row89\" class=\"row_heading level0 row89\" >89</th>\n",
       "      <td id=\"T_c4eae_row89_col0\" class=\"data row89 col0\" >большой</td>\n",
       "      <td id=\"T_c4eae_row89_col1\" class=\"data row89 col1\" >76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row90\" class=\"row_heading level0 row90\" >90</th>\n",
       "      <td id=\"T_c4eae_row90_col0\" class=\"data row90 col0\" >отношение</td>\n",
       "      <td id=\"T_c4eae_row90_col1\" class=\"data row90 col1\" >76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row91\" class=\"row_heading level0 row91\" >91</th>\n",
       "      <td id=\"T_c4eae_row91_col0\" class=\"data row91 col0\" >многий</td>\n",
       "      <td id=\"T_c4eae_row91_col1\" class=\"data row91 col1\" >75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row92\" class=\"row_heading level0 row92\" >92</th>\n",
       "      <td id=\"T_c4eae_row92_col0\" class=\"data row92 col0\" >друг</td>\n",
       "      <td id=\"T_c4eae_row92_col1\" class=\"data row92 col1\" >75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row93\" class=\"row_heading level0 row93\" >93</th>\n",
       "      <td id=\"T_c4eae_row93_col0\" class=\"data row93 col0\" >подпись</td>\n",
       "      <td id=\"T_c4eae_row93_col1\" class=\"data row93 col1\" >74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row94\" class=\"row_heading level0 row94\" >94</th>\n",
       "      <td id=\"T_c4eae_row94_col0\" class=\"data row94 col0\" >изображение</td>\n",
       "      <td id=\"T_c4eae_row94_col1\" class=\"data row94 col1\" >74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row95\" class=\"row_heading level0 row95\" >95</th>\n",
       "      <td id=\"T_c4eae_row95_col0\" class=\"data row95 col0\" >ребенок</td>\n",
       "      <td id=\"T_c4eae_row95_col1\" class=\"data row95 col1\" >73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row96\" class=\"row_heading level0 row96\" >96</th>\n",
       "      <td id=\"T_c4eae_row96_col0\" class=\"data row96 col0\" >описывать</td>\n",
       "      <td id=\"T_c4eae_row96_col1\" class=\"data row96 col1\" >73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row97\" class=\"row_heading level0 row97\" >97</th>\n",
       "      <td id=\"T_c4eae_row97_col0\" class=\"data row97 col0\" >выглядеть</td>\n",
       "      <td id=\"T_c4eae_row97_col1\" class=\"data row97 col1\" >73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row98\" class=\"row_heading level0 row98\" >98</th>\n",
       "      <td id=\"T_c4eae_row98_col0\" class=\"data row98 col0\" >типичный</td>\n",
       "      <td id=\"T_c4eae_row98_col1\" class=\"data row98 col1\" >72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c4eae_level0_row99\" class=\"row_heading level0 row99\" >99</th>\n",
       "      <td id=\"T_c4eae_row99_col0\" class=\"data row99 col0\" >комикс</td>\n",
       "      <td id=\"T_c4eae_row99_col1\" class=\"data row99 col1\" >72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x157bbe350>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрим самые часто встречающиеся слова и уберем их\n",
    "import collections\n",
    "\n",
    "meme_data['meaning_list'] = meme_data['meaning'].apply(lambda x:x.split())\n",
    "top = collections.Counter([item for sublist in meme_data['meaning_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(100))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0efee3e6-2aed-4822-a42b-89cf376a9bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#добавим наиболее встречающиеся слова, которые не несут смысловой нагрузки (обновим список стоп-слов)\n",
    "\n",
    "#temp.Common_words.values\n",
    "\n",
    "new_stopwords = ['мема', 'который', 'ситуация',\n",
    "       'использоваться', 'часто', 'показывать', 'чтото',\n",
    "       'например', 'картинка',\n",
    "       'использовать', 'мем', 'шутка', 'также', 'смысл',\n",
    "       'высмеивать',\n",
    "       'обычно', '—',\n",
    "       'просто', 'делать', 'игра', 'любой', 'очень', 'выражать', 'означать',\n",
    "       'правило', 'случай', 'иллюстрировать', 'образ', \n",
    "       'различный', 'являться', 'качество', 'ироничный', 'иметь', 'время',\n",
    "       'изза', 'поэтому', \n",
    "       'значение', 'тема', 'ктото', 'формат',\n",
    "       'выражение', \n",
    "       'оригинальный', 'кадр', 'явление', 'начинать', 'символизировать',\n",
    "       'обыгрывать',\n",
    "       'описывать', 'выглядеть', 'типичный', 'пример', 'тренд']\n",
    "\n",
    "for i_word in new_stopwords:\n",
    "    stop_words.append(i_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac940d-e064-4ea8-b91a-d3c3c76299a8",
   "metadata": {},
   "source": [
    "#### Создадим функцию, которая объединяет все шаги чистки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeac3610-b810-4113-bd06-916fa21d312d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = remove_symbols(text)\n",
    "    text = lemmatize_text(text)\n",
    "    text = remove_stopword(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c01b118-0f14-4ba3-89b3-9200b65ca41c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x дорогой y x важный y постироничный делаться намеренно кривой шрифт обрезать текст персонаж отметать основной предпочтение говорить любовь чемуто стыдный смешной'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "clean_text(meme_data['meaning'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9713a78-d97f-4766-aae5-e0bb94ac9b28",
   "metadata": {},
   "source": [
    "В качестве эксперимента также решила объединить столбцы со значением мема и его заголовком, т.к. чаще всего в заголовке уже содержится какая-то важная информация о значении мема. Но это также особо не улучшило результаты поиска. Скорее всего из-за того, что в описаниях мемов чаще всего уже упоминается его название."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "37cff526-cba0-4617-aec6-3c71a13410a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# создадим ф-ю которая добавляет заголовок в столбец со значением \n",
    "def add_header(df):\n",
    "    \n",
    "    header = df.header\n",
    "    meaning = df.meaning\n",
    "    new_text = ''\n",
    "    \n",
    "    for i_word in header.split():\n",
    "        if i_word not in meaning:\n",
    "            new_text = new_text + i_word + ' '\n",
    "    \n",
    "    new_text += meaning\n",
    "    return new_text\n",
    "\n",
    "#почистим все данные\n",
    "meme_data['header'] = meme_data['header'].apply(lambda x: clean_text(x))\n",
    "meme_data['meaning'] = meme_data['meaning'].apply(lambda x: clean_text(x))\n",
    "meme_data['meaning'] = meme_data[['header','meaning']].apply(lambda x: add_header(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe340ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['link', 'meaning', '__index_level_0__'],\n",
       "    num_rows: 2243\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#преобразуем дату в датасет hugginface для дальнейшего поиска faiss\n",
    "\n",
    "meme_dataset = Dataset.from_pandas(meme_data[['link', 'meaning']])\n",
    "meme_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88406021-0f97-45f0-ae1d-1ef34c4783b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Используем готовые модели без дополнительного дообучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f0827-c2ec-4f7a-9c0e-d184545d67dc",
   "metadata": {},
   "source": [
    "#### Выбор модели.\n",
    "\n",
    "*Основные моменты*:\n",
    "- Я решаю задачу симметричного семантического поиска (длина запроса соразмерна длине ответа (текстового описания мема)).\n",
    "- Модель должна подходить для русского языка.\n",
    "- Для поиска нужны эмбеддинги предложений, в некоторых моделях такой output отсутсвует, может потребоваться pooling для усреднения эмбеддингов слов.\n",
    "- Некоторые модели ожидают специальные токены на входных предложениях (например query/passage)\n",
    "- Существуют Cased (регистр слов не имеет значения) и uncased (слова должны быть в нижнем регистре) модели.\n",
    "\n",
    "#### Важный момент - оценка качества модели.\n",
    "- Мой датасет небольшой (около 2000 образцов), и там нет разметки (например, коэффициента, показывающего, насколько конкретный мем подходит к определенному запросу пользователя). Такая разметка планируется в будущем, для этого я буду собирать реакции реальных пользователей на предложенные мемы в моем телеграм-боте.\n",
    "- Оценить, насколько хорошо отработала модель, я смогла только полагаясь на свои субъективные ощущения.\n",
    "- Я считала модель подходящей, если она подбирает более-менее релевантные к запросу мемы. \n",
    "- Я составила список примеров пользовательских запросов, на которых сравнивала разные модели.\n",
    "\n",
    "**Вот некоторые примеры, на которых я проводила сравнение:**\n",
    "- Моя реакция, когда забыл выключить утюг перед тем, как уйти из дома\n",
    "- Когда ты готовился к экзамену всю ночь, а на следующий день узнаешь, что экзамен перенесли\n",
    "- Иду на свидание чтобы покушать\n",
    "- Мое лицо, когда друзья рассказывают про свои приключения на отдыхе, а я не ездил никуда."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c1ed1-668e-4ebc-a927-680f58cf2b92",
   "metadata": {},
   "source": [
    "#### Модели, которые я использовала (в качестве примера оставила код для первых двух, для остальных процесс похож):\n",
    "- [sentence-transformers/distiluse-base-multilingual-cased-v1](https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v1)\n",
    "- [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large) (оказалась наиболее подходящей, далее я также использовала версии base и small)\n",
    "- [DeepPavlov/rubert-base-cased](https://huggingface.co/DeepPavlov/rubert-base-cased)\n",
    "- [DeepPavlov/rubert-base-cased-conversational](https://huggingface.co/DeepPavlov/rubert-base-cased-conversational)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3db85-d51f-4efd-a9c2-bd5f9736580f",
   "metadata": {},
   "source": [
    "#### Model 1 sentence-transformers/distiluse-base-multilingual-cased-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca7aca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model_ckpt = \"sentence-transformers/distiluse-base-multilingual-cased-v1\" \n",
    "tokenizer_distiluse = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model_distiluse = TFAutoModel.from_pretrained(model_ckpt, from_pt=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124aea4-686e-420e-8083-1c6a2d2d2d86",
   "metadata": {},
   "source": [
    "### Подготовка эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58c2053b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# по умолчанию модель будет векторизировать каждое слово, поэтому нам надо усреднить значения и получить эмбединги предложений\n",
    "# будем использовать метод CLS pooling на outputs нашей модели.  \n",
    "# собираем last hidden state где содержится [CLS] token\n",
    "\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "# функция, которая токенизирует данные и возвращает эмбеддинг предложения\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer_distiluse(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"tf\"\n",
    "    )\n",
    "    encoded_input = {k: v for k, v in encoded_input.items()}\n",
    "    model_output = model_distiluse(**encoded_input)\n",
    "    return cls_pooling(model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d083feb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#протестируем на одном образце\n",
    "embedding = get_embeddings(meme_dataset[\"meaning\"][0])\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17ce31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# получаем эмбеддинги предложений для всего датасета\n",
    "# переводим значения в numpy формат, чтобы затем передать в faiss \n",
    "\n",
    "embeddings_dataset = meme_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"meaning\"]).numpy()[0]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93f642",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# добавляем к датасету faiss index (особая структура данных которая позволяет выполнять поиск эмбедингов наиболее похожих на эмбединг нашего запроса)\n",
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd12932-db62-4098-8188-8e353cbad572",
   "metadata": {},
   "source": [
    "#### Поиск с помощью FAISS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "288bd374",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEME: озадаченный широкий реакция странный непонятный\n",
      "SCORE: 8.46925163269043\n",
      "LINK: https://memepedia.ru/ozadachennyj-kot-za-stolom/\n",
      "==================================================\n",
      "\n",
      "MEME: умирающий тони старок условно разделять тип\n",
      "SCORE: 8.136177062988281\n",
      "LINK: https://memepedia.ru/umirayushhij-toni-stark/\n",
      "==================================================\n",
      "\n",
      "MEME: несмотря оба танос идти друг друг становиться отдельный\n",
      "SCORE: 7.759411811828613\n",
      "LINK: https://memepedia.ru/realnost-polna-razocharovanij/\n",
      "==================================================\n",
      "\n",
      "MEME: понимать насмешка человек сначала говорить противоречить свой\n",
      "SCORE: 7.482399940490723\n",
      "LINK: https://memepedia.ru/vy-ne-ponimaete-eto-drugoe/\n",
      "==================================================\n",
      "\n",
      "MEME: текст звучать следующий\n",
      "SCORE: 6.23533821105957\n",
      "LINK: https://memepedia.ru/govoryu-muzhu/\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"мы\"\n",
    "\n",
    "# чистим текст запроса. Важный момент - на этом этапе я еще экспериментировала с чисткой данных, далее от нее отказалась.\n",
    "question = clean_text(question)\n",
    "\n",
    "# создаем эмбединг нашего запроса\n",
    "question_embedding = get_embeddings([question]).numpy()\n",
    "question_embedding.shape\n",
    "\n",
    "# теперь будем выполнять поиск ближайших соседей к этому эмбедингу с помощью ф-ии get_nearest_examples()\n",
    "# функция возвращает кортеж:\n",
    "# (коэффициент сходства запроса и найденных эмбеддингов, топ-5 наиболее подходящих значений)\n",
    "\n",
    "\n",
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)\n",
    "\n",
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"MEME: {row.meaning}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"LINK: {row.link}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ed9c2-8be4-4d15-bbb9-aba0e0ec015b",
   "metadata": {},
   "source": [
    "#### Model 2 https://huggingface.co/intfloat/multilingual-e5-large\n",
    "\n",
    "##### Здесь процесс не отличается от предыдущей модели за исключением некоторых моментов:\n",
    "- Модель ожидает токен 'query:' в предложениях запросов пользователя и токен 'passage:' в предложениях ответов (текстовые описания мемов).\n",
    "- В описании к модели сказано, что для симметричного поиска и запрос, и ответ должны содержать токен 'query:'. Я попробовала разные варианты и пришла к выводу, что лучше придерживаться схемы из предыдущего пункта\n",
    "- В выходных слоях модели уже есть слой sentence_embedding, поэтому пулинг для усреднения не нужен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfa523-8e50-4442-9ff5-1bdfd64ebe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорты\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1b41a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# загрузка модели и токенайзера\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_e5_large = SentenceTransformer(\"intfloat/multilingual-e5-large\")\n",
    "tokenizer_e5_large = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9aa154dc-41b8-40a3-ad73-a3887f0d60da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ф-я получения эмбеддингов\n",
    "def get_embedding_e5_large_original(input_texts):\n",
    "    tokenized_input = tokenizer_e5_large(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    model_outputs = model_e5_large(tokenized_input)\n",
    "    sentence_embedding = model_outputs.sentence_embedding.detach().numpy()\n",
    "    return sentence_embedding\n",
    "    \n",
    "#example\n",
    "input_texts = all_data[\"passage\"][0]\n",
    "get_embedding_e5_large_original(input_texts).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "83e41ce5-b180-427b-a47c-db1fa53abefe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# добавим префикс query: согласно требованиям модели\n",
    "\n",
    "# Use \"query: \" and \"passage: \" correspondingly for asymmetric tasks such as passage retrieval in open QA, ad-hoc information retrieval.\n",
    "# Use \"query: \" prefix for symmetric tasks such as semantic similarity, bitext mining, paraphrase retrieval.\n",
    "# Use \"query: \" prefix if you want to use embeddings as features, such as linear probing classification, clustering.\n",
    "\n",
    "\n",
    "def add_prefix(text):\n",
    "    text = 'passage: '+text\n",
    "    return text\n",
    "\n",
    "meme_data[\"passage\"] = meme_data['meaning'].apply(lambda x: add_prefix(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09154dd7-07c8-4756-b85a-aa22e9f158eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['link', 'passage'],\n",
       "    num_rows: 2153\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# преобразуем дату в датасет hugginface\n",
    "\n",
    "meme_dataset_e5_large = Dataset.from_pandas(all_data[['link', 'passage']])\n",
    "meme_dataset_e5_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d3d057a-8b08-423a-936e-e72a1b8e2f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2243 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# получаем эмбеддинги датасета и добавляем к нашему датасету faiss index \n",
    "embeddings_dataset_e5_large2 = meme_dataset_e5_large2.map(\n",
    "    lambda x: {\"embeddings\": get_embedding_e5_large(x[\"passage\"])[0]}\n",
    ")\n",
    "\n",
    "embeddings_dataset_e5_large.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fc41d29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEME: passage: Мем по своей сути похож на мем со Светящимся мозгом, который также призван в\n",
      "несерьезной форме демонстрировать интеллектуальное превосходство.\n",
      "SCORE: 0.3387693762779236\n",
      "LINK: https://memepedia.ru/whomst/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем стали искажать, подставляя вместо “поделать” другие глаголы. Так, теперь модно стало говорить (по крайней мере, пока в онлайне) “ля шо бы поделат”, ля шо бы поест”, “ля шо бы послушат”. Никакого дополнительного смысла этот мем не несет.\n",
      "SCORE: 0.35138118267059326\n",
      "LINK: https://memepedia.ru/lya-sho-by-podelat/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем с озадаченным котом в широком смысле можно использовать как реакцию на что-то странное, непонятное.\n",
      "SCORE: 0.35262662172317505\n",
      "LINK: https://memepedia.ru/ozadachennyj-kot-za-stolom/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем способен высмеять любые проявления ненормального поведения, от которого люди буквально срываются на крик. Всего лишь два кадра с этой сцены могут затронуть серьезные социальные темы или же известные исторические ситуации. Достаточно лишь заменить лица злой сорвавшейся матери и обезумевшего сына на подходящие под ситуацию образы.\n",
      "SCORE: 0.35294485092163086\n",
      "LINK: https://memepedia.ru/why-can-t-you-just-be-normal/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Этот мем может использоваться как самостоятельно, то есть, подаваться в ответ на различные утверждения, так и быть частью придуманного диалога или подходящей по смыслу ситуации. \n",
      "SCORE: 0.35784173011779785\n",
      "LINK: https://memepedia.ru/ah-i-see-you-re-a-man-of-culture-as-well/\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# процесс поиска\n",
    "question = 'query: '+all_data['example'][4]\n",
    "\n",
    "#создаем эмбединг нашего запроса\n",
    "question_embedding = get_embedding_e5_large_original([question])\n",
    "question_embedding.shape\n",
    "\n",
    "scores, samples = embeddings_dataset_e5_large.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=True, inplace=True)\n",
    "\n",
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"MEME: {row.passage}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"LINK: {row.link}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d999d80-4a7a-4fdc-ba33-8957ea373e48",
   "metadata": {},
   "source": [
    "## 3. Fine-tuning моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea69ba23-49aa-4e79-a445-1c7c81f6e19c",
   "metadata": {},
   "source": [
    "1. На данном этапе я уже дополнила свой датасет примерами пользовательских запросов к каждому из мемов (столбец example в датафрейме) с помощью chatgpt.\n",
    "2. Буду дообучать модель *multilingual-e5-large* на этом датасете.\n",
    "3. Loss для обучения. Поскольку в датасете нет score, который бы показывал сходство между мемом и запросом пользователя, то наиболее подходящий loss - *MultipleNegativesRankingLoss*.\n",
    "\n",
    "- Формирование пар: В процессе обучения для каждого положительного примера (например, текста запроса) алгоритм автоматически выбирает отрицательные примеры из других примеров в том же батче. Таким образом, все остальные примеры в батче, кроме соответствующего положительного, рассматриваются как отрицательные.\n",
    "- Расчет потерь: Для каждой пары положительного и отрицательного примеров модель вычисляет сходство (обычно это косинусное сходство векторов, представляющих эти примеры). Целью является максимизация сходства между положительными парами и минимизация сходства между положительным и отрицательными примерами.\n",
    "- Обучение модели: В процессе обучения модель стремится расположить векторы так, чтобы векторы положительных примеров были ближе друг к другу в векторном пространстве, а векторы отрицательных примеров – как можно дальше. Это достигается путем минимизации функции потерь.\n",
    "- Применение softmax и логарифмирование: После вычисления сходства для всех пар в батче, применяется функция softmax для преобразования этих сходств в вероятностное распределение. Затем, вычисляется логарифм вероятности правильной пары (положительного примера). Функция потерь стремится минимизировать отрицательный логарифм этой вероятности.\n",
    "\n",
    "Ссылка на ресурс https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875b6339-ac20-4fe1-9613-1e97cde3840c",
   "metadata": {},
   "source": [
    "#### 1. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0de1d2c0-730e-4c8f-9cae-79fa9368310c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>header</th>\n",
       "      <th>link</th>\n",
       "      <th>meaning</th>\n",
       "      <th>example</th>\n",
       "      <th>passage</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>А мне X дороже Y</td>\n",
       "      <td>https://memepedia.ru/a-mne-x-dorozhe-y/</td>\n",
       "      <td>Мем “А мне X дороже Y” (или “А мне X важнее Y”...</td>\n",
       "      <td>Ты обеспокоен экологией? А мне смешные кошки в...</td>\n",
       "      <td>passage: Мем “А мне X дороже Y” (или “А мне X ...</td>\n",
       "      <td>query: Ты обеспокоен экологией? А мне смешные ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Рыба с большой головой смотрит на дайвера</td>\n",
       "      <td>https://memepedia.ru/ryba-s-bolshoj-golovoj-sm...</td>\n",
       "      <td>В мемах, где рыба с большой головой смотрит на...</td>\n",
       "      <td>Твой младший братик наблюдает за тобой, пока т...</td>\n",
       "      <td>passage: В мемах, где рыба с большой головой с...</td>\n",
       "      <td>query: Твой младший братик наблюдает за тобой,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Две девушки в черных платьях</td>\n",
       "      <td>https://memepedia.ru/dve-devushki-v-chernyx-pl...</td>\n",
       "      <td>Мем “Две девушки в черных платьях” показывает ...</td>\n",
       "      <td>На собеседовании два кандидата: одна пришла в ...</td>\n",
       "      <td>passage: Мем “Две девушки в черных платьях” по...</td>\n",
       "      <td>query: На собеседовании два кандидата: одна пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Пивной ежик</td>\n",
       "      <td>https://memepedia.ru/pivnoj-ezhik/</td>\n",
       "      <td>Мем “Пивной ежик” – это забавный тренд, которы...</td>\n",
       "      <td>Ты просыпаешься по утрам, открываешь новостной...</td>\n",
       "      <td>passage: Мем “Пивной ежик” – это забавный трен...</td>\n",
       "      <td>query: Ты просыпаешься по утрам, открываешь но...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Война древних русов с ящерами</td>\n",
       "      <td>https://memepedia.ru/vojna-drevnix-rusov-s-yas...</td>\n",
       "      <td>Война древних русов с ящерами или битва русов ...</td>\n",
       "      <td>На семейном ужине старший родственник рассказы...</td>\n",
       "      <td>passage: Война древних русов с ящерами или бит...</td>\n",
       "      <td>query: На семейном ужине старший родственник р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>133</td>\n",
       "      <td>Мальчик у доски</td>\n",
       "      <td>https://memepedia.ru/malchik-u-doski/</td>\n",
       "      <td>Картинку с мальчиком у доски и словом “Тут” из...</td>\n",
       "      <td>Тот момент, когда ты понимаешь, что любовь к п...</td>\n",
       "      <td>passage: Картинку с мальчиком у доски и словом...</td>\n",
       "      <td>query: Тот момент, когда ты понимаешь, что люб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>134</td>\n",
       "      <td>Не расстраивай Леонида Аркадьевича</td>\n",
       "      <td>https://memepedia.ru/ne-rasstraivaj-leonida-ar...</td>\n",
       "      <td>Мем “Не расстраивай Леонида Аркадьевича” испол...</td>\n",
       "      <td>Когда кто-то опять не выключил свет в ванной. ...</td>\n",
       "      <td>passage: Мем “Не расстраивай Леонида Аркадьеви...</td>\n",
       "      <td>query: Когда кто-то опять не выключил свет в в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>134</td>\n",
       "      <td>Девочка с хвостиками</td>\n",
       "      <td>https://memepedia.ru/mem-devochka-s-xvostikami/</td>\n",
       "      <td>Мем с девочкой с хвостиками используется для в...</td>\n",
       "      <td>Когда ты пытаешься объяснить, почему опять опо...</td>\n",
       "      <td>passage: Мем с девочкой с хвостиками используе...</td>\n",
       "      <td>query: Когда ты пытаешься объяснить, почему оп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>134</td>\n",
       "      <td>Танец Медведева</td>\n",
       "      <td>https://memepedia.ru/tanec-medvedeva/</td>\n",
       "      <td>Шутки про танец Медведева обычно используют, ч...</td>\n",
       "      <td>Когда ты на вечеринке и DJ включает твою любим...</td>\n",
       "      <td>passage: Шутки про танец Медведева обычно испо...</td>\n",
       "      <td>query: Когда ты на вечеринке и DJ включает тво...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>134</td>\n",
       "      <td>Мем он (девушка шепчет подруге на ухо)</td>\n",
       "      <td>https://memepedia.ru/mem-on-devushka-shepchet-...</td>\n",
       "      <td>Мем “Девушка шепчет на ухо подруге” использует...</td>\n",
       "      <td>Её подруге: 'Ты знаешь, что он сказал про свой...</td>\n",
       "      <td>passage: Мем “Девушка шепчет на ухо подруге” и...</td>\n",
       "      <td>query: Её подруге: 'Ты знаешь, что он сказал п...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2153 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      page                                     header  \\\n",
       "0        1                           А мне X дороже Y   \n",
       "1        1  Рыба с большой головой смотрит на дайвера   \n",
       "2        1               Две девушки в черных платьях   \n",
       "3        1                                Пивной ежик   \n",
       "4        1              Война древних русов с ящерами   \n",
       "...    ...                                        ...   \n",
       "2148   133                            Мальчик у доски   \n",
       "2149   134         Не расстраивай Леонида Аркадьевича   \n",
       "2150   134                       Девочка с хвостиками   \n",
       "2151   134                            Танец Медведева   \n",
       "2152   134     Мем он (девушка шепчет подруге на ухо)   \n",
       "\n",
       "                                                   link  \\\n",
       "0               https://memepedia.ru/a-mne-x-dorozhe-y/   \n",
       "1     https://memepedia.ru/ryba-s-bolshoj-golovoj-sm...   \n",
       "2     https://memepedia.ru/dve-devushki-v-chernyx-pl...   \n",
       "3                    https://memepedia.ru/pivnoj-ezhik/   \n",
       "4     https://memepedia.ru/vojna-drevnix-rusov-s-yas...   \n",
       "...                                                 ...   \n",
       "2148              https://memepedia.ru/malchik-u-doski/   \n",
       "2149  https://memepedia.ru/ne-rasstraivaj-leonida-ar...   \n",
       "2150    https://memepedia.ru/mem-devochka-s-xvostikami/   \n",
       "2151              https://memepedia.ru/tanec-medvedeva/   \n",
       "2152  https://memepedia.ru/mem-on-devushka-shepchet-...   \n",
       "\n",
       "                                                meaning  \\\n",
       "0     Мем “А мне X дороже Y” (или “А мне X важнее Y”...   \n",
       "1     В мемах, где рыба с большой головой смотрит на...   \n",
       "2     Мем “Две девушки в черных платьях” показывает ...   \n",
       "3     Мем “Пивной ежик” – это забавный тренд, которы...   \n",
       "4     Война древних русов с ящерами или битва русов ...   \n",
       "...                                                 ...   \n",
       "2148  Картинку с мальчиком у доски и словом “Тут” из...   \n",
       "2149  Мем “Не расстраивай Леонида Аркадьевича” испол...   \n",
       "2150  Мем с девочкой с хвостиками используется для в...   \n",
       "2151  Шутки про танец Медведева обычно используют, ч...   \n",
       "2152  Мем “Девушка шепчет на ухо подруге” использует...   \n",
       "\n",
       "                                                example  \\\n",
       "0     Ты обеспокоен экологией? А мне смешные кошки в...   \n",
       "1     Твой младший братик наблюдает за тобой, пока т...   \n",
       "2     На собеседовании два кандидата: одна пришла в ...   \n",
       "3     Ты просыпаешься по утрам, открываешь новостной...   \n",
       "4     На семейном ужине старший родственник рассказы...   \n",
       "...                                                 ...   \n",
       "2148  Тот момент, когда ты понимаешь, что любовь к п...   \n",
       "2149  Когда кто-то опять не выключил свет в ванной. ...   \n",
       "2150  Когда ты пытаешься объяснить, почему опять опо...   \n",
       "2151  Когда ты на вечеринке и DJ включает твою любим...   \n",
       "2152  Её подруге: 'Ты знаешь, что он сказал про свой...   \n",
       "\n",
       "                                                passage  \\\n",
       "0     passage: Мем “А мне X дороже Y” (или “А мне X ...   \n",
       "1     passage: В мемах, где рыба с большой головой с...   \n",
       "2     passage: Мем “Две девушки в черных платьях” по...   \n",
       "3     passage: Мем “Пивной ежик” – это забавный трен...   \n",
       "4     passage: Война древних русов с ящерами или бит...   \n",
       "...                                                 ...   \n",
       "2148  passage: Картинку с мальчиком у доски и словом...   \n",
       "2149  passage: Мем “Не расстраивай Леонида Аркадьеви...   \n",
       "2150  passage: Мем с девочкой с хвостиками используе...   \n",
       "2151  passage: Шутки про танец Медведева обычно испо...   \n",
       "2152  passage: Мем “Девушка шепчет на ухо подруге” и...   \n",
       "\n",
       "                                                  query  \n",
       "0     query: Ты обеспокоен экологией? А мне смешные ...  \n",
       "1     query: Твой младший братик наблюдает за тобой,...  \n",
       "2     query: На собеседовании два кандидата: одна пр...  \n",
       "3     query: Ты просыпаешься по утрам, открываешь но...  \n",
       "4     query: На семейном ужине старший родственник р...  \n",
       "...                                                 ...  \n",
       "2148  query: Тот момент, когда ты понимаешь, что люб...  \n",
       "2149  query: Когда кто-то опять не выключил свет в в...  \n",
       "2150  query: Когда ты пытаешься объяснить, почему оп...  \n",
       "2151  query: Когда ты на вечеринке и DJ включает тво...  \n",
       "2152  query: Её подруге: 'Ты знаешь, что он сказал п...  \n",
       "\n",
       "[2153 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('all_data.csv', sep='\\t', index_col=0)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb8e06-b575-4353-b679-543dbe559af6",
   "metadata": {},
   "source": [
    "### Варианты обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea05f2-95db-4c06-b717-d574dda66faf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Можно дообучать модель с помощью одной из 2х библиотек - sentence-transformer (более простой) или transformer (более гибкий, возможна доп. настройка)\n",
    "- sentence-transformer - загружаем модель через model = SentenceTransformer('intfloat/multilingual-e5-large'). Токенайзер подгружается автоматически\n",
    "- transformer - загружаем модель через AutoModel + AutoTokenizer  \n",
    "\n",
    "- важный момент: когда мы загружаем модель через AutoModel нужно дополнительно подгрузить модель или ф-ю для пулинга (усреднения токенов по предложениям). НО для дообучения пулинг не нужен, т.к. важнее чтобы модель училась на уровне токенов. через SentenceTransformer пулинг слои обычно подгружаются сами - эта библиотека подходит для быстрого использования уже готовых моделей для работы с предложениями\n",
    "\n",
    "#### 2. Датасет оборачиваем в генератор DataLoader в обоих случаях (для MultipleNegativesRankingLoss лучше выбрать NoDublicatesDataloader)\n",
    "- sentence-transformer - каждый пример оборачиваем в класс InputExample\n",
    "- transformer - можно сделать кастомный класс Dataset, чтобы уместить туда токенайзер и сделать датасет из пандас датафрейма\n",
    "\n",
    "#### 3. Используем MultipleNegativesRankingLoss \n",
    "- позитивные пары ближе друг к другу в векторном пространстве, а негативные дальше\n",
    "- мой датасет состоит только из позитивных пар query-passage. MultipleNegativesRankingLoss сам подберет негативные \n",
    "- batch_size может влиять на кач-во обучения, т.к. больший пакет подберет больше негативных примеров\n",
    "- если примеры очень похожи, то модель может иметь трудности с тем, чтобы различать примеры\n",
    "\n",
    "#### 4. Валидация модели\n",
    "- в моем датасете примерно 2000 примеров. более того, он будет в дальнейшем использоваться для поиска faiss. каждый из них ценен, поэтому делить на train-val довольно трудно\n",
    "- 1. ВАРИАНТ - вообще не делить, но кач-во можно будет проверить только при поиске FAISS (не очень удобно, нужно ждать пока модель обучится и непонятно, сколько ее обучать, не переобучилась ли она)\n",
    " \n",
    "Для следующих вариантов нужна разметка (например, 0-предложения не схожи, 1-предложения схожи))\n",
    "- 2. ВАРИАНТ - разделить в соотношении 90-10. НО все равно какие-то примеры не попадут в выборку\n",
    "- 3. ВАРИАНТ - кросс-валидация - делить датасет на 5 или 10 частей и обучаться на каждой из 5 выборок, затем усреднить оценку\n",
    "\n",
    "\n",
    "#### 5. Метрики\n",
    "- пока что у меня нет явных labels, поэтому в качестве основной метрики можно использовать только loss в процессе обучения\n",
    "- как вариант использовать EmbeddingSimilarityEvaluator - метрика, которая будет оценивать, насколько точно модель определяет сходство между примерами (нужна разметка)\n",
    "- можно сравнивать среднее расстояние между эмбеддингами позитивных пар и/или асстояние между эмбеддингами позитивных и случайно выбранных негативных пар (нужен валидационный датасет)\n",
    "\n",
    "#### 6. Нужно ли чистить данные? \n",
    "- Трансформеры устроены таким образом, что чистить не обязательно, они могут улавливать определенные закономерности текста. \n",
    "- Однако ссылки и какой-то технический шум лучше удалить\n",
    "\n",
    "#### 7. Какой batch_size использовать? \n",
    "- Лучше начать со стандартного 16 или 32. \n",
    "- чем больше, тем быстрее обучение, но нужно больше эпох\n",
    "- но слишком большие пакеты могут ухудшить обучение\n",
    "\n",
    "#### 8. Сколько эпох? \n",
    "- Я выбрала вариант обучать по 3 эпохи, затем смотреть на результаты поиска и обучать дальше\n",
    "\n",
    "#### 9. Что дальше?\n",
    "- улучшать FAISS - с помощью настройки\n",
    "- разметить данные искусственно - добавить негативные примеры и оценки\n",
    "- можно попробовать Cross-encoder models для искусственной разметки датасета (однако для этого часть датасета должна быть уже размечена, поэтому нужен следующий пункт:)\n",
    "- система обратной связи - ответ пользователя, является ли мем релевантным или нет (таким образом можно будет разметить часть датасета с помощью реальных пользователей и их запросов)\n",
    "- фильтрация и ранжирование: Помимо основного поиска по эмбеддингам, можно добавить дополнительные фильтры или ранжирование на основе дополнительных критериев, таких как популярность мема, дата создания и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4665c4a-71dc-4ce6-90a7-07871d078f58",
   "metadata": {},
   "source": [
    "Метрики, которые могут быть в дальнейшем использованы, если появится больше данных для валидационного датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b129e2-5b7c-45ca-b7f0-5aa3e3898cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cреднее расстояние между эмбеддингами позитивных пар:\n",
    "#Если это расстояние маленькое, это может указывать на то, что модель правильно \"понимает\" схожесть позитивных пар.\n",
    "\n",
    "total_distance = 0\n",
    "for example in val_examples:\n",
    "    query_embedding = model.encode(example.texts[0])\n",
    "    passage_embedding = model.encode(example.texts[1])\n",
    "    distance = np.linalg.norm(query_embedding - passage_embedding)\n",
    "    total_distance += distance\n",
    "average_distance = total_distance / len(val_examples)\n",
    "print(\"Average distance for positive pairs:\", average_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e11780-c170-46c1-be0f-abd9544f9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расстояние между эмбеддингами позитивных и случайно выбранных негативных пар:\n",
    "#Если это расстояние значительно больше, чем для позитивных пар, это хороший знак. Это означает, что модель может различать позитивные и негативные примеры.\n",
    "\n",
    "total_distance = 0\n",
    "num_neg_samples = 0\n",
    "for example in val_examples:\n",
    "    query_embedding = model.encode(example.texts[0])\n",
    "    random_passage = df.sample().iloc[0]['passage']  # выбор случайного passage из всего датасета\n",
    "    random_passage_embedding = model.encode(random_passage)\n",
    "    distance = np.linalg.norm(query_embedding - random_passage_embedding)\n",
    "    total_distance += distance\n",
    "    num_neg_samples += 1\n",
    "average_distance = total_distance / num_neg_samples\n",
    "print(\"Average distance for random negative pairs:\", average_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a41c50-656e-4310-a5e8-c25b7e8f024a",
   "metadata": {},
   "source": [
    "#### 2. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d6f977-cc1a-451a-9c75-5f7f6512a947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Создание обучающего датасета\n",
    "train_examples = [InputExample(texts=[row['query'], row['passage']]) for _, row in all_data[['query', 'passage']].iterrows()]\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69b133-5d8d-4329-8dfe-47bdc58fd6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Загрузка модели \n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "\n",
    "# Определение функции потерь\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# Обучение модели\n",
    "num_epochs = 3\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps, \n",
    "          show_progress_bar=True)\n",
    "\n",
    "os.makedirs('search', exist_ok=True)\n",
    "model.save('search/search-model2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3085379-de41-4b8b-8f4e-34ab477ec559",
   "metadata": {},
   "source": [
    "#### 3. Добавляем faiss индекс в новый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0451e64-b98f-40d8-96b7-04ad2620b880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создадим ф-ю получения эмбеддингов для новой модели\n",
    "\n",
    "tokenizer_e5_large = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "\n",
    "def get_embedding_e5_large(input_texts):\n",
    "    tokenized_input = tokenizer_e5_large(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    model_outputs = model(tokenized_input)\n",
    "    sentence_embedding = model_outputs.sentence_embedding.detach().numpy()\n",
    "    return sentence_embedding\n",
    "    \n",
    "#example\n",
    "input_texts = all_data[\"meaning\"][0]\n",
    "get_embedding_e5_large(input_texts).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d7823-6dad-4d1c-ae6c-e1c8093efe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meme_dataset_faiss = Dataset.from_pandas(all_data[['link', 'query', 'passage']])\n",
    "meme_dataset_faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e0a034f-72ec-47e0-aaba-4afae84e5c89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meme_dataset_faiss = meme_dataset_faiss.map(\n",
    "    lambda x: {\"embeddings\": get_embedding_e5_large(x[\"passage\"])[0]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f095c8-8bd5-4e1a-82b2-c559f291d4d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#добавляем faiss index\n",
    "meme_dataset_faiss.add_faiss_index(column=\"embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb4c11e0-2408-4a75-be19-d3370bf8b79f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEME: passage: Тест “На кого из знаменитостей вы похожи?” появился на корейском развлекательном сайте Vonvon 17 марта 2017 года. Приложение быстро стало вирусным среди западных пользователей интернета. Но не из-за его реалистичности, а потому, что оно выдавало притянутые результаты. Так, если загрузить фото чернокожего мужчины, собаки или женщины из Китая, приложение все равно покажет, что вы похожи на Леонардо ДиКаприо или Марго Робби. Похоже, в его базе не так много селебрити, и поэтому все видят одни и те же итоговые картинки.\n",
      "SCORE: 1.0769195556640625\n",
      "LINK: https://memepedia.ru/na-kogo-iz-znamenitostej-vy-poxozhi/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Летом 2018 года появилась фотожаба с лицом Илона Маска, прифотошопленным на фото рэпера Post Malone. Юмор в том, что с заменой лица мало что изменилось.\n",
      "SCORE: 1.1951813697814941\n",
      "LINK: https://memepedia.ru/fotozhaby-s-licom-ilona-maska/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем с Рикардой построен на сходстве девушки с Рикардо Милосом. Kalinka Fox не просто скопировала костюм, но и смогла передать движения и настроение бразильского танцора. Правда, фанаты мемов про Рикардо не оценили его женскую версию. Поэтому большинство мемов высмеивают эту пародию.\n",
      "SCORE: 1.2101337909698486\n",
      "LINK: https://memepedia.ru/rikarda/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Любовь Соболь и Ксения Собчак, которые выглядят как клоны, заставили людей вспоминить всех похожих знаменитостей. Например, Киру Найтли и Натали Портман. Также в ход пошли мемы про двух одинаковых героев. Например, мем с двумя Спайдерменами. Или мем, где\n",
      "SCORE: 1.2142326831817627\n",
      "LINK: https://memepedia.ru/debaty-sobchak-i-sobol/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем про Базза Лайтера, который смотрит на костюм, это формат, в котором оригинал меняют с помощью фотошопа, чтобы показать других персонажей массовой культуры.\n",
      "SCORE: 1.248395562171936\n",
      "LINK: https://memepedia.ru/bazz-lajter-smotrit-na-kostyum/\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = 'query: '+'Когда решил попробовать новую прическу, а друзья сравнивают тебя с известной личностью, но не в лучшем ее виде'\n",
    "\n",
    "#создаем эмбединг запроса\n",
    "question_embedding = get_embedding_e5_large([question])\n",
    "question_embedding.shape\n",
    "\n",
    "# поиск\n",
    "scores, samples = meme_dataset_faiss.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=True, inplace=True)\n",
    "\n",
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"MEME: {row.passage}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"LINK: {row.link}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd07195-3cf8-4eb2-bf64-94c85506d609",
   "metadata": {},
   "source": [
    "#### 4. Продолжение обучения модели (далее шаги повторяются)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7bbd3bd6-b863-475f-80af-986315ac9a67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e2d0ff3c4342448bcc05fb25d2f74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7337953b0ed4713853e223c99a36a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c527d8baaa54256b8cbc7b47c4768c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd89257e82543828567e4dc5fe63881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузка модели \n",
    "model2 = SentenceTransformer('search/search-model2')\n",
    "\n",
    "# Определение функции потерь\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model2)\n",
    "\n",
    "# Обучение модели\n",
    "num_epochs = 3\n",
    "\n",
    "model2.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs, \n",
    "          show_progress_bar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad536c26-8dde-46c3-a84d-e2b01bd15547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.save('search/search-model2-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5273041-823a-41be-b6a2-bbdf1c51fa2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# новая ф-я получения эмбеддингов\n",
    "def get_embedding_e5_large_trained2(input_texts):\n",
    "    tokenized_input = tokenizer_e5_large(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    model_outputs = model2(tokenized_input)\n",
    "    sentence_embedding = model_outputs.sentence_embedding.detach().numpy()\n",
    "    return sentence_embedding\n",
    "\n",
    "meme_dataset_trained2 = Dataset.from_pandas(all_data[['link', 'passage']])\n",
    "\n",
    "meme_dataset_trained2 = meme_dataset_trained2.map(\n",
    "    lambda x: {\"embeddings\": get_embedding_e5_large_trained2(x[\"passage\"])[0]}\n",
    ")\n",
    "\n",
    "#добавляем к нашему датасету faiss index (особая структура данных которая позволяет выполнять поиск эмбедингов \n",
    "#наиболее похожих на эмбединг нашего запроса)\n",
    "meme_dataset_trained2.add_faiss_index(column=\"embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8e7604b-c4cf-4ada-b23a-254544b29ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEME: passage: Тест “На кого из знаменитостей вы похожи?” появился на корейском развлекательном сайте Vonvon 17 марта 2017 года. Приложение быстро стало вирусным среди западных пользователей интернета. Но не из-за его реалистичности, а потому, что оно выдавало притянутые результаты. Так, если загрузить фото чернокожего мужчины, собаки или женщины из Китая, приложение все равно покажет, что вы похожи на Леонардо ДиКаприо или Марго Робби. Похоже, в его базе не так много селебрити, и поэтому все видят одни и те же итоговые картинки.\n",
      "SCORE: 1.0796183347702026\n",
      "LINK: https://memepedia.ru/na-kogo-iz-znamenitostej-vy-poxozhi/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем про “барби шоп” высмеивает нелепые прически парней. Нередко там появляются совсем пародийные картинки. Сам текст стал вирусной пастой, его пишут обычные пользователи, иронизируя над тем, как их плохо постригли.\n",
      "SCORE: 1.1855273246765137\n",
      "LINK: https://memepedia.ru/sxodil-v-etot-vash-barbi-shop/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Флешмоб с переделыванием лиц Эльзы и других диснеевских принцесс начинался как призыв смотреть на женщин более реалистично и отказаться от недостижимых стандартов красоты.\n",
      "SCORE: 1.2347406148910522\n",
      "LINK: https://memepedia.ru/ya-vot-sela-i-peredelala-lica/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Любовь Соболь и Ксения Собчак, которые выглядят как клоны, заставили людей вспоминить всех похожих знаменитостей. Например, Киру Найтли и Натали Портман. Также в ход пошли мемы про двух одинаковых героев. Например, мем с двумя Спайдерменами. Или мем, где\n",
      "SCORE: 1.257300853729248\n",
      "LINK: https://memepedia.ru/debaty-sobchak-i-sobol/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем с Рикардой построен на сходстве девушки с Рикардо Милосом. Kalinka Fox не просто скопировала костюм, но и смогла передать движения и настроение бразильского танцора. Правда, фанаты мемов про Рикардо не оценили его женскую версию. Поэтому большинство мемов высмеивают эту пародию.\n",
      "SCORE: 1.266979694366455\n",
      "LINK: https://memepedia.ru/rikarda/\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#поиск\n",
    "\n",
    "question = 'query: '+'Когда решил попробовать новую прическу, а друзья сравнивают тебя с известной личностью, но не в лучшем ее виде'\n",
    "\n",
    "#создаем эмбединг нашего запроса\n",
    "question_embedding = get_embedding_e5_large_trained2([question])\n",
    "question_embedding.shape\n",
    "\n",
    "#теперь будем выполнять поиск ближайших соседей к этому эмбедингу с помощью ф-ии get_nearest_examples()\n",
    "# The Dataset.get_nearest_examples() возвращает кортеж:\n",
    "#(коэффициент сходства запроса и эмбедингов, топ-5 наиболее подходящих значений)\n",
    "\n",
    "\n",
    "scores, samples = meme_dataset_trained2.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=True, inplace=True)\n",
    "\n",
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"MEME: {row.passage}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"LINK: {row.link}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2344ae4-f34d-483e-9df7-e12e534383b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# дальнейшее обучение модели\n",
    "model3 = SentenceTransformer('search/search-model2-1')\n",
    "\n",
    "# Определение функции потерь\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model3)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "model3.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs, \n",
    "          show_progress_bar=True)\n",
    "\n",
    "model3.save('search/search-model2-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601369fa-ff50-4a4e-adc6-999528cdbb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ф-я получения эмбеддингов с новой версией модели\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model3 = SentenceTransformer('search/search-model2-2')\n",
    "tokenizer_e5_large = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "\n",
    "def get_embedding_e5_large_trained3(input_texts):\n",
    "    tokenized_input = tokenizer_e5_large(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    model_outputs = model3(tokenized_input)\n",
    "    sentence_embedding = model_outputs.sentence_embedding\n",
    "    \n",
    "    #нормализуем эмбеддинг\n",
    "    sentence_embedding = F.normalize(sentence_embedding, p=2, dim=1)\n",
    "    return sentence_embedding.detach().numpy()\n",
    "\n",
    "meme_dataset_trained3 = Dataset.from_pandas(all_data[['link', 'passage']])\n",
    "\n",
    "meme_dataset_trained3 = meme_dataset_trained3.map(\n",
    "    lambda x: {\"embeddings\": get_embedding_e5_large_trained3(x[\"passage\"])[0]}\n",
    ")\n",
    "\n",
    "#добавляем faiss index\n",
    "meme_dataset_trained3.add_faiss_index(column=\"embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "306743ef-cc6d-4082-a855-a8f5f4e4fc7a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEME: passage: Мем “Крош орет” или “Крош кричит” иллюстрирует ситуации, когда человеку так плохо, что ему ничего не остается кроме того, как кричать. Это могут быть и гиперболизированные ситуации, когда ты узнаешь о дополнительном уроке. Аналогичный мем из прошлого – с кричащим ковбоем из клипа Big Enough Джимми Барнас.\n",
      "SCORE: 1.2425875663757324\n",
      "LINK: https://memepedia.ru/krosh-krichit/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мемы с плачущим Макконахи – реакция человека на что-то упущенное, обидное. Часто их используют в ироническом ключе, “заставляя” Купера плакать, например, из-за трейлера новых “Звездных войн”.\n",
      "SCORE: 1.2528679370880127\n",
      "LINK: https://memepedia.ru/makkonaxi-plachet/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем “Давайте после майских” – это ироничная отмазка от любой, самой незначительной задачи. В интернете принято высмеивать тех, кто постоянно откладывает дела из-за приближающихся праздников. Причем начинают это делать обычно задолго до самих выходных.\n",
      "SCORE: 1.2533793449401855\n",
      "LINK: https://memepedia.ru/davajte-posle-majskix/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем “Уровень стресса 99%” используется для иллюстрации ситуаций, в которых человек испытывает предельно высокую нервную нагрузку, и обычно задействует элемент преувеличения. Изображение применяется и в качестве картинки-реакции, и в качестве самостоятельных мемов, и одинаково популярно и на Западе, и в России.\n",
      "SCORE: 1.280809760093689\n",
      "LINK: https://memepedia.ru/uroven-stressa-99/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем “Грустный Бэтмен” популярен, поскольку известный актер в образе не менее известного персонажа запечатлен в очень выразительной позе. С ним делают фотожабы и добавляют к грустному Бэтмену надписи, показывающие ситуации, в которых человек может испытывать такие эмоции.\n",
      "SCORE: 1.2974947690963745\n",
      "LINK: https://memepedia.ru/sad-batman/\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# поиск\n",
    "question = 'query: '+'Когда ты готовился к экзамену всю ночь, а на следующий день узнаешь, что экзамен перенесли'\n",
    "\n",
    "#создаем эмбединг нашего запроса\n",
    "question_embedding = get_embedding_e5_large_trained3([question])\n",
    "question_embedding.shape\n",
    "\n",
    "scores, samples = meme_dataset_trained3.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=True, inplace=True)\n",
    "\n",
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"MEME: {row.passage}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"LINK: {row.link}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed0442-96e7-4470-bc30-6988b6e70a91",
   "metadata": {},
   "source": [
    "### 4. Дополнительная настройка FAISS \n",
    "\n",
    "Я попробовала 2 вида индексов FAISS и не заметила никакой разницы между результатами:\n",
    "- faiss.IndexFlatIP - Косинусное сходство измеряет угол между двумя векторами, не учитывая их длину. После L2 нормализации все вектора имеют единичную длину, что делает их сравнение на основе косинусного сходства более эффективным. В этом случае, расстояние между векторами определяется исключительно углом между ними.\n",
    "- faiss.IndexFlatL2 - Евклидово расстояние измеряет прямое расстояние между двумя точками в пространстве. Когда применяется L2 нормализация, уменьшается влияние различий в длине векторов, делая расстояния более схожими с углами, измеряемыми при косинусном сходстве.\n",
    "- Такой результат получился т.к., после l2 нормализации обе метрики становятся идентичными, т.к. они учитывают только направление векторов, а не их длину\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52fc858a-0511-42d9-bacc-6ee5a16f3a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#загрузка модели и токенайзера\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model3 = SentenceTransformer('search/search-model2-2')\n",
    "tokenizer_e5_large = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "\n",
    "def get_embedding_e5_large_trained3(input_texts):\n",
    "    tokenized_input = tokenizer_e5_large(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    model_outputs = model3(tokenized_input)\n",
    "    sentence_embedding = model_outputs.sentence_embedding\n",
    "    #нормализуем эмбеддинг\n",
    "    sentence_embedding = F.normalize(sentence_embedding, p=2, dim=1) \n",
    "    return sentence_embedding.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a62a029-c567-4bdd-a418-1259c62bd712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# подготовка датасета и получение эмбеддингов\n",
    "import faiss\n",
    "from datasets import Dataset\n",
    "\n",
    "meme_dataset_trained3 = Dataset.from_pandas(all_data[['link', 'passage']])\n",
    "\n",
    "meme_dataset_trained3 = meme_dataset_trained3.map(\n",
    "    lambda x: {\"embeddings\": get_embedding_e5_large_trained3(x[\"passage\"])[0]}\n",
    ")\n",
    "embeddings = np.vstack(meme_dataset_trained3['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8906db4-5001-42bb-9efb-e4a231ec2c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# определяем индекс faiss\n",
    "index = faiss.IndexFlatIP(1024) #мера схожести - косинусное расстояние\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa87b576-56e6-47c8-bacd-f74f9bbdab36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEME: passage: Тренд “Первое свидание” иронично показывает разницу между парнями и девушками. Тогда как девушки на первое свиданиe одеваются эффектно, мужчины в мемах предпочитают самые безумные и нестандартные наряды. Часто чтобы это показать, используют кадры из игр, фильмов и сериалов.\n",
      "SCORE: 0.4013262987136841\n",
      "LINK: https://memepedia.ru/pervoe-svidanie-ona-i-ya/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем с девочкой, которая убегает после поцелуя, используется для высмеивания парней, испытывающих проблемы в общении с противоположным полом. Сам момент выглядит довольно комично, плюс внимание привлекают эмоции на лице разочарованного парнишки.\n",
      "SCORE: 0.3746700882911682\n",
      "LINK: https://memepedia.ru/devochka-ubegaet-ot-malchika-posle-poceluya/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Слово “кусь” – это сокращение от слова “укус”, но значения у него могут быть самыми разными. Прежде всего, “кусь” означает легкий укус как проявление симпатии. Также это слово может означать поцелуй и использоваться вместо приветствия.\n",
      "SCORE: 0.3661344647407532\n",
      "LINK: https://memepedia.ru/kus/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Толстый кот в слюнявчике, который спрашивает: “Есть чо покушот?” – мем об любви к еде. Его используют для ситуаций, когда очень хочется есть, но еду еще не дали. Или чтобы показать, что ты любишь еду и всегда готов покушать.\n",
      "SCORE: 0.3460671305656433\n",
      "LINK: https://memepedia.ru/est-cho-pokushot/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем “Возьми ее за талию” – это классическая конструкция с неожиданной развязкой. Читатель смотрит первые три панели, но никак не ожидает увидеть на четвертой что-то, не связанное с романтикой. За счет этого создается комический эффект.\n",
      "SCORE: 0.3164202570915222\n",
      "LINK: https://memepedia.ru/vozmi-ee-za-taliyu-prityani-k-sebe-podnimi-ee/\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ищем ближайших соседей в FAISS индексе на основании IndexFlatIP (косинусное сходство)\n",
    "question = 'query: '+'иду на свидание чтобы покушать'\n",
    "\n",
    "#создаем эмбединг нашего запроса\n",
    "question_embedding = get_embedding_e5_large_trained3([question])\n",
    "\n",
    "k = 5  # Количество ближайших соседей\n",
    "distances, indices = index.search(question_embedding, k)\n",
    "\n",
    "# Создание нового DataFrame с результатами поиска\n",
    "result_df = pd.DataFrame({'query_link': [all_data['link'][i] for i in indices[0]],\n",
    "                           'query_passage': [all_data['passage'][i] for i in indices[0]],\n",
    "                           'distance': distances[0]})\n",
    "\n",
    "result_df = result_df.sort_values('distance', ascending=False)\n",
    "\n",
    "for _, row in result_df.iterrows():\n",
    "    print(f\"MEME: {row.query_passage}\")\n",
    "    print(f\"SCORE: {row.distance}\")\n",
    "    print(f\"LINK: {row.query_link}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc44dc00-66d4-40b3-bdc7-a70d39380009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# мера схожести - евклидово расстояние\n",
    "index2 = faiss.IndexFlatL2(1024) \n",
    "index2.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aca362a2-2b26-438c-afde-fde109a7049b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEME: passage: Тренд “Первое свидание” иронично показывает разницу между парнями и девушками. Тогда как девушки на первое свиданиe одеваются эффектно, мужчины в мемах предпочитают самые безумные и нестандартные наряды. Часто чтобы это показать, используют кадры из игр, фильмов и сериалов.\n",
      "SCORE: 1.1973477602005005\n",
      "LINK: https://memepedia.ru/pervoe-svidanie-ona-i-ya/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем с девочкой, которая убегает после поцелуя, используется для высмеивания парней, испытывающих проблемы в общении с противоположным полом. Сам момент выглядит довольно комично, плюс внимание привлекают эмоции на лице разочарованного парнишки.\n",
      "SCORE: 1.2506600618362427\n",
      "LINK: https://memepedia.ru/devochka-ubegaet-ot-malchika-posle-poceluya/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Слово “кусь” – это сокращение от слова “укус”, но значения у него могут быть самыми разными. Прежде всего, “кусь” означает легкий укус как проявление симпатии. Также это слово может означать поцелуй и использоваться вместо приветствия.\n",
      "SCORE: 1.2677311897277832\n",
      "LINK: https://memepedia.ru/kus/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Толстый кот в слюнявчике, который спрашивает: “Есть чо покушот?” – мем об любви к еде. Его используют для ситуаций, когда очень хочется есть, но еду еще не дали. Или чтобы показать, что ты любишь еду и всегда готов покушать.\n",
      "SCORE: 1.3078656196594238\n",
      "LINK: https://memepedia.ru/est-cho-pokushot/\n",
      "==================================================\n",
      "\n",
      "MEME: passage: Мем “Возьми ее за талию” – это классическая конструкция с неожиданной развязкой. Читатель смотрит первые три панели, но никак не ожидает увидеть на четвертой что-то, не связанное с романтикой. За счет этого создается комический эффект.\n",
      "SCORE: 1.3671596050262451\n",
      "LINK: https://memepedia.ru/vozmi-ee-za-taliyu-prityani-k-sebe-podnimi-ee/\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ищем ближайших соседей в FAISS индексе на основании IndexFlatL2 (евклидово расстояние)\n",
    "question = 'query: '+'иду на свидание чтобы покушать'\n",
    "\n",
    "#создаем эмбединг нашего запроса\n",
    "question_embedding = get_embedding_e5_large_trained3([question])\n",
    "\n",
    "k = 5  # Количество ближайших соседей\n",
    "distances, indices = index2.search(question_embedding, k)\n",
    "\n",
    "# Создание нового DataFrame с результатами поиска\n",
    "result_df = pd.DataFrame({'query_link': [all_data['link'][i] for i in indices[0]],\n",
    "                           'query_passage': [all_data['passage'][i] for i in indices[0]],\n",
    "                           'distance': distances[0]})\n",
    "\n",
    "result_df = result_df.sort_values('distance', ascending=True)\n",
    "\n",
    "for _, row in result_df.iterrows():\n",
    "    print(f\"MEME: {row.query_passage}\")\n",
    "    print(f\"SCORE: {row.distance}\")\n",
    "    print(f\"LINK: {row.query_link}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c6393a-48cb-4dd9-8949-f15f57e134d2",
   "metadata": {},
   "source": [
    "- Далее я решила проверить, используется ли в базовой модели нормализация по умолчанию?\n",
    "- Вывод: да, в данной модели из библиотеки sentence-transformers она используется, поэтому нет разницы между использованием IndexFlatIP и IndexFlatL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c5b6b6-d088-4c82-8e82-42a8b51e9363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999994 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# проверка нормы векторов\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "sentences = [\"Пример предложения\", \"Еще одно предложение\"]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Проверка нормы эмбеддингов\n",
    "norms = np.linalg.norm(embeddings, axis=1)\n",
    "print(norms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eeeb7f-235c-409c-bc02-316d7cdd5645",
   "metadata": {},
   "source": [
    "### 5. Подготовка к деплою"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753d534-187f-4838-8cba-a5dca9020e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение эмбеддингов обученной модели\n",
    "embeddings = np.vstack(meme_dataset_trained3['embeddings'])\n",
    "np.save('embeddings.npy', embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f341d-455c-415b-8632-33cbed589fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# экспорт модели в onnx-формат (для оптимизации размера докер-контейнера)\n",
    "import torch.onnx\n",
    "\n",
    "input_texts = 'Привет как дела'\n",
    "inp = tokenizer(input_texts, max_length=128, padding=\"max_length\", truncation=True, return_tensors='np')\n",
    "input_ids = inp.input_ids\n",
    "attention_mask = inp.attention_mask\n",
    "dummy_input = (input_ids, attention_mask)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"small_model3.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67eda97-9714-43ec-9a83-d69d016efdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример инференса с помощью onnx-сессии\n",
    "ort_session = ort.InferenceSession(\"small_model3.onnx\")\n",
    "text = \"query: Когда ты готовился к экзамену всю ночь, а на следующий день узнаешь, что экзамен перенесли\"\n",
    "inputs = tokenizer(text, max_length=128, padding=\"max_length\", truncation=True, return_tensors='np')\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: inputs['input_ids'],\n",
    "              ort_session.get_inputs()[1].name: inputs['attention_mask']}\n",
    "\n",
    "sentence_embeddings = ort_session.run(None, ort_inputs)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
